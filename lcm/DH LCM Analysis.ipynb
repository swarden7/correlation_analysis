{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71c1eeb4-6b67-4c24-81f1-913cf39b10bf",
   "metadata": {},
   "source": [
    "### Life Cycle Management Data Analysis ðŸŒ½\n",
    "Considerations:\n",
    "- This notebook is intended for the analysis of Double Haploid Life Cycle Management experiments developed in GTES between 2021 and 2024\n",
    "- The dataset used is `full_lcm_data.csv` obtained from the notebook `DH LCM Data Merger`\n",
    "- The unique identifier for an Induction Plant is 'IND-ID' column.\n",
    "- Dataset columns are grouped by 4 main processes, which are named as prefix in each column (__*IND*__: Induction, __*LAB*__: Laboratory, __*HRD*__: Hardening, __*BN*__: Baby Nursery)\n",
    "- Datapoints of Hardening and Baby Nursery have relationship *many-to-one* with Induction and Laboratory datapoints, which were repeated to fill blank values.\n",
    "- This means that in __Induction and Laboratory datapoints, each plant is repeated many times, and not always the same number of times. Need to select unique values of IND-ID for a proper analysis of corresponding columns.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fb1180-3889-44a7-9460-39ecc6d67163",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Function for installing dependencies from requirements.txt\n",
    "import subprocess\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "import statsmodels.api as sm\n",
    "import itertools\n",
    "def install_requirements(file_path):\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-r', file_path])\n",
    "\n",
    "#if libraries not installed, execute the code below this comment    \n",
    "#install_requirements('requirements.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13d3ff2-339f-43a2-b1b5-25bac62546a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Fetching data from csv\n",
    "full_data = pd.read_csv('full_lcm_data.csv', low_memory=False)\n",
    "data_info = full_data.info()\n",
    "data_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc4c43e-0f6d-4651-b5d7-1dfea7d5c58f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Quick overview of dataset\n",
    "unique_ind_data = full_data.drop_duplicates(subset=['IND-ID'])\n",
    "total_ind_plants = full_data['IND-ID'].nunique()\n",
    "first_sow = full_data['IND_Sowing_Date'].min()\n",
    "last_sow = full_data['IND_Sowing_Date'].max()\n",
    "germinated_plants = unique_ind_data[unique_ind_data['IND_%Germin.']==1]['IND-ID'].nunique()\n",
    "pollinated_plants = unique_ind_data[unique_ind_data['IND_%Pollination']==1]['IND-ID'].nunique()\n",
    "ears_harvested = unique_ind_data[unique_ind_data['IND_Ear_harvested']==True]['IND-ID'].nunique()\n",
    "material_count = full_data['IND_Induction_MATID'].nunique()\n",
    "total_embryos = unique_ind_data['LAB_#Total_Embryos'].sum()\n",
    "haploid_embryos = unique_ind_data['LAB_#Haploids_Embryos'].sum()\n",
    "selected_seedlings = unique_ind_data['LAB_Total_selected_seedlings'].sum()\n",
    "print(f'**HOW MANY INDUCTION PLANTS ARE IN THIS DATASET?** \\nTotal Materials: {material_count} different materials')\n",
    "print(f'- {total_ind_plants} Induction plants were sowed (first sow on {first_sow}, last sow on {last_sow})\\n- {germinated_plants} Induction plants germinated (Germination rate: {germinated_plants/total_ind_plants:.2%})')\n",
    "print(f'- {pollinated_plants} Induction plants successfully pollinated (Pollination rate: {pollinated_plants/germinated_plants:.2%})')\n",
    "print(f'- {ears_harvested} Induction plants successfully harvested (Harvest rate: {ears_harvested/pollinated_plants:.2%})')\n",
    "print(f'- {int(total_embryos)} Embryos processed ({int(haploid_embryos)} Haploids, Haploidy rate: {haploid_embryos/total_embryos:.2%} )')\n",
    "print(f'- {int(selected_seedlings)} Seedlings selected')\n",
    "full_data.groupby(['IND_Planting_number','IND_Induction_MATID'])['IND_Induction_MATID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3abbe0e-1be4-47dc-8faf-3d7a2a569084",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Identification and visualization of significant correlations using Pearson's correlation coefficient\n",
    "#Calculation is done in every combination possible for all numeric columns, \n",
    "#saves in a table the significant correlations and create a dispersion chart\n",
    "correlation_data = []\n",
    "float_columns = full_data.select_dtypes(include=['float64']).columns\n",
    "color_segmentation = 'IND_Planting_number'\n",
    "mapping = {\n",
    "    '1st Planting': 1, \n",
    "    '2nd Planting': 2, \n",
    "    '3rd Planting': 3, \n",
    "    '4th Planting': 4,\n",
    "    '5th Planting': 5, \n",
    "    '6th Planting': 6, \n",
    "    '7th Planting': 7, \n",
    "    '8th Planting': 8,\n",
    "    '9th Planting': 9, \n",
    "    '10th Planting': 10, \n",
    "    '11th Planting': 11, \n",
    "    '12th Planting': 12,\n",
    "    '13th Planting': 13}  \n",
    "\n",
    "full_data['encoded_planting_number'] = full_data['IND_Planting_number'].map(mapping)\n",
    "num_colors = len(full_data['encoded_planting_number'].unique())\n",
    "cmap = plt.cm.get_cmap('jet', num_colors)\n",
    "\n",
    "for column1 in float_columns:\n",
    "    for column2 in float_columns:\n",
    "        if column1 != column2:\n",
    "            correlation = full_data[column1].corr(full_data[column2])\n",
    "            if correlation > 0.5:\n",
    "                correlation_type = \"Positive\" if correlation > 0 else \"Negative\"\n",
    "                correlation_data.append({'column1': column1, 'column2': column2, 'correlation_type': correlation_type, 'correlation_value': correlation})\n",
    "                print(f'{correlation_type} Correlation found: {column1} vs {column2} ({correlation})')                \n",
    "                plt.figure()\n",
    "                scatter = plt.scatter(full_data[column1], full_data[column2], c=full_data['encoded_planting_number'], cmap=cmap, norm=mcolors.BoundaryNorm(np.arange(-0.5, num_colors, 1), cmap.N))\n",
    "                plt.colorbar(scatter, ticks=np.arange(0, num_colors, 1), label='Planting Number')\n",
    "                plt.xlabel(column1)\n",
    "                plt.ylabel(column2)\n",
    "                plt.title(f'{column1} vs {column2}. Pearson: {correlation}')\n",
    "                plt.show()\n",
    "\n",
    "            elif correlation < -0.5:\n",
    "                correlation_type = \"Positive\" if correlation > 0 else \"Negative\"\n",
    "                correlation_data.append({'column1': column1, 'column2': column2, 'correlation_type': correlation_type, 'correlation_value': correlation})\n",
    "                print(f'{correlation_type} Correlation found: {column1} vs {column2} ({correlation})')\n",
    "                plt.figure()\n",
    "                scatter = plt.scatter(full_data[column1], full_data[column2], c=full_data['encoded_planting_number'], cmap=cmap, norm=mcolors.BoundaryNorm(np.arange(-0.5, num_colors, 1), cmap.N))\n",
    "                plt.colorbar(scatter, ticks=np.arange(0, num_colors, 1), label='Planting Number')\n",
    "                plt.xlabel(column1)\n",
    "                plt.ylabel(column2)\n",
    "                plt.title(f'{column1} vs {column2}. Pearson: {correlation}')\n",
    "                plt.show()\n",
    "\n",
    "correlation_df = pd.DataFrame(correlation_data)\n",
    "correlation_df.to_csv('',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6fb1e2-7b99-48cb-aa3e-db03568c8461",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Table of significant correlations found in all dataset\n",
    "correlation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b6964a-e00b-4173-b8dd-de07bb1f647f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identification and visualization of significant variable relationship using linear regression\n",
    "float_columns = full_data.select_dtypes(include=['float64']).columns\n",
    "column_combinations = list(itertools.combinations(float_columns, 2))\n",
    "column_combinations_filtered = [comb for comb in column_combinations if 'IND_Plant_ID' not in comb \n",
    "                                and full_data[comb[0]].notnull().any() \n",
    "                                and full_data[comb[1]].notnull().any()]\n",
    "regression_data = []\n",
    "\n",
    "for column1, column2 in column_combinations_filtered:\n",
    "    X = full_data[[column1, column2]]\n",
    "    X = sm.add_constant(X)\n",
    "    y = full_data[column2]\n",
    "    model = sm.OLS(y, X, missing='drop').fit()\n",
    "    \n",
    "    if 0.0 < model.pvalues.iloc[1] < 0.05:  \n",
    "        pvalue = model.pvalues.iloc[1]\n",
    "        print(f\"Regression Results: {column2} as response variable and {column1} as predictor variable with p-value of {pvalue}\")        \n",
    "        regression_data.append({'column1': column1, 'column2': column2, 'coefficient': model.params[1], 'std_err':model.bse[1],'t_value': model.tvalues[1], 'p_value':model.pvalues[1]})\n",
    "        sns.lmplot(x=column1, y=column2, data=full_data, hue='encoded_planting_number', aspect=1.5, fit_reg=False, palette='viridis')\n",
    "        plt.title(f'{column2} as response variable and {column1} as predictor variable')\n",
    "        plt.show()\n",
    "        print(model.summary())\n",
    "regression_df = pd.DataFrame(regression_data)\n",
    "regression_df.rename(columns={'column1': 'predictor', 'column2': 'response'}, inplace=True)\n",
    "regression_df = regression_df.sort_values(by='std_err', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ecbd95-a41c-44a0-aaeb-d91ca8a62421",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_df = regression_df.sort_values(by='std_err', ascending=True).reset_index(drop=True)\n",
    "regression_df.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022b9a00-de53-41e1-8fc1-b8a1ac704ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_df.to_csv('correlation_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c310acdf-b83b-4235-b81f-8d45ada3e66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7bea13-fa25-4739-872c-a6422d255a29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
